var documenterSearchIndex = {"docs":
[{"location":"gating/#Gating-Function-with-Random-Effects","page":"Gating Function","title":"Gating Function with Random Effects","text":"","category":"section"},{"location":"gating/","page":"Gating Function","title":"Gating Function","text":"LogitGating\nLogitGatingSim\nLogitGatingEval\nDiagMvNormal_KL","category":"page"},{"location":"gating/#MixedLRMoE.LogitGating","page":"Gating Function","title":"MixedLRMoE.LogitGating","text":"LogitGating(α, β)\n\nCreate a struct of coefficients for a gating function with α for the fixed effects, and β for the random effects.\n\nArguments\n\nα: A matrix of coefficients for the fixed effects.\nβ: A matrix of coefficients for the random effects. If β = nothing, then the gating function does not have random effects.\n\n\n\n\n\n","category":"type"},{"location":"gating/#MixedLRMoE.LogitGatingSim","page":"Gating Function","title":"MixedLRMoE.LogitGatingSim","text":"LogitGatingSim(gate, x; re_μ_list=nothing, re_Σ_list=nothing, map_matrix=nothing, check_args=true)\n\nSimulate the gating function at x and some specifications of random effects (if provided).\n\nArguments\n\ngate: A LogitGating object.\nx: A matrix of covariates.\n\nOptional arguments\n\nre_μ_list: A list of the means of the random effects.\nre_Σ_list: A list of the diagonal covariance matrices of the random effects. By model assumption,    the random effects are assumed to be independent, so only a vector of the diagonal elements (i.e. the variances)   is needed.\nmap_matrix: a matrix that maps each observation to their corresponding factor(s) in the random effect(s).\ncheck_args: If true (default), check the validity of the arguments.\n\nReturn Values\n\nA matrix of the log probability values of the gating function.\n\n\n\n\n\n","category":"function"},{"location":"gating/#MixedLRMoE.LogitGatingEval","page":"Gating Function","title":"MixedLRMoE.LogitGatingEval","text":"LogitGatingEval(gate, x; re_list=nothing, map_matrix=nothing, check_args=true)\n\nEvaluate the gating function at x and some specifications of random effects (if provided).\n\nArguments\n\ngate: A LogitGating object.\nx: A matrix of covariates.\n\nOptional arguments\n\nre_list: A list of the realized values of of random effects.\nmap_matrix: a matrix that maps each observation to their corresponding factor(s) in the random effect(s).\ncheck_args: If true (default), check the validity of the arguments.\n\nReturn Values\n\nA matrix of the log probability values of the gating function.\n\n\n\n\n\n","category":"function"},{"location":"gating/#MixedLRMoE.DiagMvNormal_KL","page":"Gating Function","title":"MixedLRMoE.DiagMvNormal_KL","text":"DiagMvNormal_KL(μ, Σ)\n\nCalculate the KL divergence between a diagonal multivariate normal distribution and a standard normal distribution.\n\nArguments\n\nμ: A vector of means.\nΣ: A vector of the diagonal elements in the covariance matrix.\n\n\n\n\n\n","category":"function"},{"location":"framework/#Modelling-Framework","page":"Modelling Framework","title":"Modelling Framework","text":"","category":"section"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"The Mixed LRMoE model is formulated very similarly to the LRMoE model, with the addition of random effects that describe unobserved effects.","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"Let (mathbfx_i mathbfy_i) i = 1 2 dots n denote a set of observations, where mathbfx_i denotes the covariates and mathbfy_i the response(s). A vector mathbfw_i of random effects are also associated with each observation, which may be one or multiple levels with varying number of factors. A detailed description of mathbfw_i is given in Random Effects.","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"Given mathbfx_i and mathbfw_i, the i-th observation is classified into one of g latent classes by the so-called logit gating function. The probability of belonging to the j-th latent class is given by","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"pi_j(mathbfx_i mathbfw_i mathbfalpha mathbfbeta) = fracexp (mathbfalpha_j^T mathbfx_i + mathbfbeta_j^T mathbfw_i)sum_j=1^g exp (mathbfalpha_j^T mathbfx_i + mathbfbeta_j^T mathbfw_i) quad j = 1 2 dots g-1","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"For model identifiability reasons, we assume mathbfalpha_g = mathbf0 and mathbfbeta_g = mathbf0 which correspond to the reference class. We also fix mathbfbeta_1 = mathbf1 to avoid arbtrary scaling and sign-switching of the random effects.","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"Conditional on the latent class j, the distribution of the response mathbfy_i is given by an expert function with density","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"f_j(mathbfy_i mathbfpsi_j) = prod_d=1^D f_jd(mathbfy_id mathbfpsi_jd)","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"where we assume conditional independence of dimensions 1 2 dots D of mathbfy_i, if it is a vector of responses.","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"The (partial) likelihood function given the random effects mathbfw = (mathbfw_1 mathbfw_2 dots mathbfw_n) is therefore","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"L(mathbfalpha mathbfbeta mathbfpsi mathbfx mathbfw mathbfy) = prod_i=1^n left sum_j=1^g pi_j(mathbfx_i mathbfw_i mathbfalpha mathbfbeta) f_j(mathbfy_i mathbfpsi_j) right","category":"page"},{"location":"framework/","page":"Modelling Framework","title":"Modelling Framework","text":"The parameters to estimate are the regression coefficients mathbfalpha_j and mathbfbeta_j, as well as the parameters of the expert functions mathbfpsi_j, which is implemented by the a variational Expectation-Conditional-Maximization algorithm (details omitted, see Tseung et al. (2023)). Simultaneously, the approximated posterior distributions of the random effects mathbfw are also obtained, which is especially useful for making predictions.","category":"page"},{"location":"fit/#Fitting-Functions","page":"Fitting Function","title":"Fitting Functions","text":"","category":"section"},{"location":"fit/","page":"Fitting Function","title":"Fitting Function","text":"fit_exact_VI","category":"page"},{"location":"fit/#MixedLRMoE.fit_exact_VI","page":"Fitting Function","title":"MixedLRMoE.fit_exact_VI","text":"fit_exact_VI(Y, X, α_init, model, β_init, map_matrix, re_μ_list, re_Σ_list; ...)\n\nFit a Mixed LRMoE model with exact observations of Y using a variational algorithm.\n\nArguments\n\nY: A matrix of response.\nX: A matrix of covariates.\nα: A matrix of logit regression coefficients.\nmodel: A matrix specifying the expert functions.\nβ_init: a matrix of regression coefficients before the random effects.\nmap_matrix: a matrix that maps each observation to their corresponding factor(s) in the random effect(s).\nre_μ_list: a list of arrays of the variational means of random effects.\nre_Σ_list: a list of arrays of the (diagonal) variational covariance matrices of random effects.\n\nOptional Arguments\n\nexpusure: an array of numerics, indicating the time invertal over which the count data (if applicable) are collected.   If nothing is provided, it is set to 1.0 for all observations. It is assumed that all continuous expert functions are   not affected by exposure.\nn_sims: number of simulations used to approximate the expectation of the loglikelihood/Evidence Lower Bound (ELBO).\npenalty: true (default) or false, indicating whether penalty is imposed on the magnitude of parameters.\npen_α: a numeric penalty on the magnitude of logit regression coefficients. Default is 1.0.\npen_params: an array of penalty term on the magnitude of parameters of component distributions/expert functions.\nα_iter_max: Maximum number of iterations when updating α. Default is 5.\necm_iter_max: Maximum number of iterations of the ECM algorithm. Default is 200.\nprint_steps: true (default) or false, indicating whether intermediate updates of parameters should be logged.\n\nReturn Values\n\nα_fit: Fitted values of logit regression coefficients α.\nβ_fit: Fitted values of regression coefficients β.\ncomp_dist: Fitted parameters of expert functions.\nre_μ_list: a list of arrays of the variational means of random effects.\nre_Σ_list: a list of arrays of the (diagonal) variational covariance matrices of random effects.\nll_history: a vector of the history of ELBO of the fitted model at each iteration.\niter: Number of iterations passed in the fitting function.\nll: Loglikelihood of the fitted model (with penalty on the magnitude of parameters).\nll_np: Loglikelihood of the fitted model (without penalty on the magnitude of parameters).\n\n\n\n\n\n","category":"function"},{"location":"#MixedLRMoE-Package","page":"Overview","title":"MixedLRMoE Package","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"MixedLRMoE is an extention to the LRMoE package in order to incorporate random effects, which are especially useful for  modelling multilevel data usually observed in insurance and many other general statistical applications.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"The theoretical development of Mixed LRMoE (or Mixed Mixture of Experts, MMoE in short) is given in Fung and Tseung (2022+), where it is shown to possess the desirable property of denseness. In other words, the Mixed LRMoE model has a potential  to accurately resemble almost all characteristics inherited in multilevel data, including the marginal distributions, dependence structures, regression links, random intercepts and random slopes. In a particular case where the multilevel data is hierarchical, we further show that a nested version of the MMoE universally approximates a broad range of dependence structures of the random effects among different factor levels.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"An application of the Mixed LRMoE in insurance contexts is given in Tseung et al. (2023), where the model is shown to outperform classical benchmark models (Generalized Linear (Mixed) Models, or GL(M)M in short) for better differentiation of risky and safe drivers in a real-world dataset, as well as providing intuitive and interpretable ratemaking results that accurately reflect the unobserved heterogeneity of the drivers' risk profiles.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"MixedLRMoE mainly provides a fitting function to obtain the model parameters and approximated posterior distributions of the random effects, which is documented in this website. The MixedLRMoE package depends on LRMoE for the implementation of various expert functions and other internal and external utilities. For the overlapping functionalities (e.g. supported expert functions, model initialization, penalization of expert functions, predictions, etc.), please refer to the LRMoE documentation.","category":"page"},{"location":"random_effects/#Random-Effects","page":"Random Effects","title":"Random Effects","text":"","category":"section"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"Below are two classical examples where random effects are used for modelling unobserved effects. We also illustrate how they are represented in the MixedLRMoE.jl package.","category":"page"},{"location":"random_effects/#Panel-Data","page":"Random Effects","title":"Panel Data","text":"","category":"section"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"In a panel data study, suppose there are N_1 unique individuals in a population of size n, where each individual may be observed multiple times.","category":"page"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"We assume the individual-level unobserved effects are w_1^(l)_l = 1 2 dots N_1, where the subscript 1 denotes the first (and only, in this example) level of random effects and the superscript (l) indicates the l-th level, i.e. the l-th unique individual.\nFor each observation i, mathbfw_i = (w_i1) is a one-element vector that contains the unobserved effect of the i-th observation, where w_i1 in w_1^(l)_l = 1 2 dots N_1.\nCorrespondingly, we could construct a n-length mapping vector t_1 such that the i-th element maps observation i to one of the levels in w_1^(l)_l = 1 2 dots N_1.","category":"page"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"Suppose we have a dataframe of the insurance claim history for the following individuals across different years, where the number of drivers N_1 = 3 and the number of observations n = 10.","category":"page"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"Observation Driver Year ... (other columns)\n1 Amy 2015 ...\n2 Amy 2016 ...\n3 Amy 2017 ...\n4 Bob 2014 ...\n5 Bob 2015 ...\n6 Bob 2016 ...\n7 Bob 2017 ...\n8 Bob 2018 ...\n9 Sam 2018 ...\n10 Sam 2019 ...","category":"page"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"We represent the driver-level random effects by a set of random variables  w_1^(1) w_1^(2) w_1^(3) , for Amy, Bob and Sam respectively. For convenience (also generality, see the next example), this is represented by a vector/tuple of vectors re_list = [w_1] where w_1 = [w_11, w_12, w_13] in the package implementation.","category":"page"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"The mapping vector is constructed as t_1 = [1, 1, 1, 2, 2, 2, 2, 2, 3, 3]. For convenience (also generality, see the next example), this is reshaped as a n-by-1 matrix mapping_matrix = hcat(t_1) in the package implementation.","category":"page"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"Correspondingly, the mapped vectors of random effects to each observation are mathbfw_i = (w_1^(1)) for i = 1 2 3 (Amy), mathbfw_i = (w_1^(2)) for i = 4 5 dots 8 (Bob), and mathbfw_i = (w_1^(3)) for i = 9 10 (Sam).","category":"page"},{"location":"random_effects/#Hierarchical-Data","page":"Random Effects","title":"Hierarchical Data","text":"","category":"section"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"We consider a more complex hierarchical data structure with two levels of random effects. A classical example is the school-teacher effects on student performance (see e.g. here), whereby the teacher-level random effects are nested within the school-level random effects (assuming each teacher only works at one school). The same hierarchical data structure can be used to model many other scenarios, such as country-(province/state)-city effects on the probability of fire accidents.","category":"page"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"Let us consider a Canadian province-city data.","category":"page"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"We assume the province-level unobserved effects are w_1^(l)_l = 1 2 dots N_1, where the subscript 1 denotes the first level of random effects and the superscript (l) indicates the l-th level, i.e. the l-th province.\nWe also assume the city-level unobserved effects are w_2^(l)_l = 1 2 dots N_2, where the subscript 2 denotes the second level of random effects and the superscript (l) indicates the l-th level, i.e. the l-th city. Note that cities are nested within provinces, i.e. each city belongs to one and only one province.\nFor each observation i, mathbfw_i = (w_i1 w_i2) is a two-element vector that contains the unobserved effects of the i-th observation, where w_i1 in w_1^(l)_l = 1 2 dots N_1 (province) and w_i2 in w_2^(l)_l = 1 2 dots N_2 (city).\nCorrespondingly, we could construct two n-length mapping vectors t_1 and t_2 to map each observation to one of the levels in w_1^(l)_l = 1 2 dots N_1 and w_2^(l)_l = 1 2 dots N_2 respectively.","category":"page"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"Suppose we have a dataframe of fire accidents history for the following cities across different provinces in Canada, where the number of provinces N_1 = 2, the number of cities N_2 = 4 and the number of observations n = 10.","category":"page"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"Observation Province City Year ... (other columns)\n1 Ontario Toronto 2019 ...\n2 Ontario Toronto 2020 ...\n3 Ontario Ottawa 2019 ...\n4 Ontario Ottawa 2020 ...\n5 Ontario Ottawa 2021 ...\n6 Quebec Montreal 2018 ...\n7 Quebec Montreal 2019 ...\n8 Quebec Montreal 2020 ...\n9 Quebec Quebec City 2019 ...\n10 Quebec Quebec City 2020 ...","category":"page"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"We represent the province-level random effects by a set of random variables  w_1^(1) w_1^(2) , for Ontario and Quebec respectively, and the city-level random effects by a set of random variables  w_2^(1) w_2^(2) w_2^(3) w_2^(4), for Toronto, Ottawa, Montreal and Quebec City respectively.","category":"page"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"These random effects are represented by a vector/tuple of vectors re_list = [w_1, w_2] where w_1 = [w_11, w_12] and w_2 = [w_21, w_22, w_23, w_24] in the package implementation.","category":"page"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"The mapping vectors are constructed as t_1 = [1, 1, 1, 1, 1, 2, 2, 2, 2, 2] and t_2 = [1, 1, 2, 2, 2, 3, 3, 3, 4, 4], which are reshaped as a n-by-2 matrix mapping_matrix = hcat(t_1, t_2) in the package implementation.","category":"page"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"Correspondingly, the mapped vectors of random effects to each observation are mathbfw_i = (w_1^(1) w_2^(1)) for i = 1 2 (Ontario-Toronto), mathbfw_i = (w_1^(1) w_2^(2)) for i = 3 4 5 (Ontario-Ottawa), mathbfw_i = (w_1^(2) w_2^(3)) for i = 6 7 8 (Quebec-Montreal), and mathbfw_i = (w_1^(2) w_2^(4)) for i = 9 10 (Quebec-Quebec City).","category":"page"},{"location":"random_effects/#Other-Generalizations","page":"Random Effects","title":"Other Generalizations","text":"","category":"section"},{"location":"random_effects/","page":"Random Effects","title":"Random Effects","text":"The above are two classical examples where random effects may be incorporated in a model. The package implementation is more general and can be applied to other scenarios, such as crossed interactions (as opposed to hierarchical), and more than two levels of random effects. In these cases, the implementations of the random effects and mapping vectors/matrix are similar to the above.","category":"page"}]
}
